{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d812b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jenny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 1: Pipeline class + MIDI‐emotion helpers (standalone)\n",
    "# (MULTI-TRACK V4 - Expanded Emotions, Enhanced Legato & Rhythmic Variety)\n",
    "\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy, textstat, random, mido, re, shutil, glob, os, stat, pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class FormAwareTextToMusic:\n",
    "    def __init__(self, base_tempo=80, tpb=480, cycles=4):\n",
    "        self.emoc_model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "        self.emoc = pipeline(\"text-classification\", model=self.emoc_model_name, return_all_scores=True)\n",
    "        self.known_emotions_from_model = list(self.emoc.model.config.label2id.keys())\n",
    "        \n",
    "        self.zs_topic = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "        self.topics = [\"love\",\"betrayal\",\"death\",\"fate\",\"family\",\"violence\", \"mystery\", \"peace\", \"tension\", \"hope\", \"despair\", \"reflection\"]\n",
    "        self.zs_form = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "        self.forms = [\"sonata\",\"etude\",\"prelude\",\"waltz\",\"nocturne\",\"fugue\", \"ballad\", \"fantasy\", \"elegy\", \"rhapsody\"]\n",
    "        self.tfidf = TfidfVectorizer(max_features=5, stop_words=\"english\", min_df=1)\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.base_tempo = base_tempo\n",
    "        self.tpb = tpb \n",
    "        self.cycles = cycles\n",
    "\n",
    "        # Added more moods, legato_intensity, base_note_duration_mult\n",
    "        self.MUSICAL_MOOD_PARAMS = { \n",
    "          \"joy\":        {\"tempo\":+20, \"vol\":(60,90),\"mel_adj\":0,  \"mel_range\": (2, 6), \"r_complex\":0.7, \"prog\": [\"I\", \"V\", \"vi\", \"IV\"], \"dyn_shape\": \"crescendo\", \"legato_i\":0.85, \"base_dur_mult\":1.0, \"is_major\":True},\n",
    "          \"sadness\":    {\"tempo\":-30, \"vol\":(30,55), \"mel_adj\":-15,\"mel_range\": (1, 2), \"r_complex\":0.15,\"prog\": [\"i\", \"iv\", \"VI\", \"V\"], \"dyn_shape\": \"diminuendo\",\"legato_i\":0.99, \"base_dur_mult\":2.0, \"is_major\":False}, # Longer notes\n",
    "          \"anger\":      {\"tempo\":+10, \"vol\":(80,100),\"mel_adj\":5,  \"mel_range\": (2, 7), \"r_complex\":0.65,\"prog\": [\"i\", \"VI\", \"bII\", \"V\"], \"dyn_shape\": \"accented\",  \"legato_i\":0.7,  \"base_dur_mult\":0.8, \"is_major\":False}, # Neapolitan for anger\n",
    "          \"fear\":       {\"tempo\": -5, \"vol\":(40,70), \"mel_adj\":-10,\"mel_range\": (1, 4), \"r_complex\":0.25,\"prog\": [\"i\", \"iidim\", \"VI\", \"V\"], \"dyn_shape\": \"subdued_var\",\"legato_i\":0.9,  \"base_dur_mult\":1.5, \"is_major\":False},\n",
    "          \"surprise\":   {\"tempo\":+15, \"vol\":(70,100),\"mel_adj\":5,  \"mel_range\": (3, 8), \"r_complex\":0.8, \"prog\": [\"I\", \"bVI\", \"IV\", \"V\"], \"dyn_shape\": \"sudden_loud\",\"legato_i\":0.75, \"base_dur_mult\":0.9, \"is_major\":True},\n",
    "          \"love\":       {\"tempo\":-10,  \"vol\":(40,70), \"mel_adj\":-5, \"mel_range\": (2, 4), \"r_complex\":0.4, \"prog\": [\"I\", \"vi\", \"ii\", \"V\"], \"dyn_shape\": \"gentle_swell\",\"legato_i\":0.95, \"base_dur_mult\":1.2, \"is_major\":True},\n",
    "          \"neutral\":    {\"tempo\":  0, \"vol\":(50,75), \"mel_adj\":-5, \"mel_range\": (2, 5), \"r_complex\":0.5, \"prog\": [\"I\", \"IV\", \"V\", \"ii\"], \"dyn_shape\": \"flat\",      \"legato_i\":0.85, \"base_dur_mult\":1.0, \"is_major\":True},\n",
    "          \"serenity\":   {\"tempo\":-35, \"vol\":(20,40), \"mel_adj\":-20,\"mel_range\": (1, 2), \"r_complex\":0.1, \"prog\": [\"Imaj7\", \"IVmaj7\", \"ii7\", \"V7sus\"], \"dyn_shape\": \"very_flat_soft\",\"legato_i\":0.99, \"base_dur_mult\":2.5, \"is_major\":True}, # Very long notes\n",
    "          \"suspense\":   {\"tempo\":-15, \"vol\":(35,60), \"mel_adj\":-15,\"mel_range\": (1, 3), \"r_complex\":0.15,\"prog\": [\"i\", \"bII\", \"Vaug\", \"i(add b6)\"], \"dyn_shape\": \"trembling\", \"legato_i\":0.8, \"base_dur_mult\":1.8, \"is_major\":False}, # Dissonant\n",
    "          \"anticipation\":{\"tempo\":+10, \"vol\":(50,80), \"mel_adj\":-5, \"mel_range\": (2,5), \"r_complex\":0.4, \"prog\": [\"IV\", \"V\", \"IV/vi\", \"V7\"], \"dyn_shape\":\"crescendo_slight\", \"legato_i\":0.8, \"base_dur_mult\":1.0, \"is_major\":True}, # Unresolved tension\n",
    "          \"trust\":      {\"tempo\": -10, \"vol\":(55,80), \"mel_adj\":-5, \"mel_range\": (1,3), \"r_complex\":0.3, \"prog\": [\"I\", \"IV\", \"V\", \"I\"], \"dyn_shape\":\"flat_warm\", \"legato_i\":0.9, \"base_dur_mult\":1.5, \"is_major\":True}, # Stable, warm\n",
    "          \"awe\":        {\"tempo\":-10, \"vol\":(60,90), \"mel_adj\":0,  \"mel_range\": (3,7), \"r_complex\":0.25,\"prog\": [\"I\", \"VI\", \"IV\", \"bVII\"], \"dyn_shape\":\"grand_swell\", \"legato_i\":0.95, \"base_dur_mult\":2.0, \"is_major\":True}, # Wider leaps, slower\n",
    "          \"remorse\":    {\"tempo\":-20, \"vol\":(30,60), \"mel_adj\":-10,\"mel_range\": (1,2), \"r_complex\":0.2, \"prog\": [\"i\", \"iv\", \"iidim\", \"V\"], \"dyn_shape\":\"diminuendo_slow\", \"legato_i\":0.98, \"base_dur_mult\":1.8, \"is_major\":False},\n",
    "          \"optimism\":   {\"tempo\":+10, \"vol\":(65,95), \"mel_adj\":0,  \"mel_range\": (2,5), \"r_complex\":0.6, \"prog\": [\"I\", \"IV\", \"V/V\", \"V\"], \"dyn_shape\":\"crescendo_bright\", \"legato_i\":0.85, \"base_dur_mult\":1.0, \"is_major\":True},\n",
    "          \"pessimism\":  {\"tempo\":-25, \"vol\":(40,65), \"mel_adj\":-8, \"mel_range\": (1,3), \"r_complex\":0.2, \"prog\": [\"i\", \"bVI\", \"iv\", \"V\"], \"dyn_shape\":\"diminuendo_heavy\", \"legato_i\":0.95, \"base_dur_mult\":1.7, \"is_major\":False},\n",
    "        }\n",
    "        # Shortened key names for brevity in MUSICAL_MOOD_PARAMS\n",
    "        # vol = base volume range for accompaniment, mel_adj = melody volume adjustment relative to this\n",
    "        # mel_range = melodic range hint, r_complex = rhythmic complexity\n",
    "        # prog = chord progression, dyn_shape = dynamic shape hint\n",
    "        # legato_i = legato intensity for melody, base_dur_mult = base note duration multiplier\n",
    "\n",
    "        self.TOPIC_PARAMS = {\n",
    "          \"love\":1.2,\"betrayal\":0.8,\"death\":0.6, \"mystery\": 0.9, \"peace\": 1.1, \"tension\":0.7,\n",
    "          \"hope\": 1.15, \"despair\":0.7, \"reflection\":0.9,\n",
    "          \"fate\":1.0,\"family\":1.1,\"violence\":0.7,\"neutral\":1.0\n",
    "        }\n",
    "        self.MAJOR_DIATONIC_CHORDS = [\"M\", \"m\", \"m\", \"M\", \"M\", \"m\", \"d\"]\n",
    "        self.MINOR_DIATONIC_CHORDS = [\"m\", \"d\", \"M\", \"m\", \"m\", \"M\", \"M\"]\n",
    "\n",
    "    def _derive_musical_mood(self, raw_emo_label, emo_scores, topic, text_keywords):\n",
    "        # emo_scores is a dict like {'joy': 0.9, 'sadness': 0.05, ...}\n",
    "        # More sophisticated mapping\n",
    "        if raw_emo_label == \"joy\":\n",
    "            if topic == \"love\": return \"love\"\n",
    "            if \"hope\" in text_keywords or topic == \"hope\": return \"optimism\"\n",
    "            return \"joy\"\n",
    "        if raw_emo_label == \"sadness\":\n",
    "            if \"sorry\" in text_keywords or \"regret\" in text_keywords : return \"remorse\"\n",
    "            if topic == \"despair\": return \"pessimism\"\n",
    "            if topic == \"peace\" or \"calm\" in text_keywords: return \"serenity\"\n",
    "            return \"sadness\"\n",
    "        if raw_emo_label == \"fear\":\n",
    "            if topic in [\"mystery\", \"tension\"]: return \"suspense\"\n",
    "            if emo_scores.get(\"surprise\", 0) > 0.3: return \"awe\" # Fear + Surprise -> Awe\n",
    "            return \"fear\"\n",
    "        if raw_emo_label == \"surprise\":\n",
    "            if emo_scores.get(\"joy\",0) > 0.3: return \"awe\" # Surprise + Joy -> Awe (more positive)\n",
    "            if topic == \"hope\": return \"optimism\"\n",
    "            return \"surprise\"\n",
    "        if raw_emo_label == \"anger\":\n",
    "            # Could check for \"betrayal\" topic to make it more specific if we had a \"betrayal\" mood\n",
    "            return \"anger\"\n",
    "        if raw_emo_label == \"neutral\":\n",
    "            if topic == \"peace\" or \"calm\" in text_keywords: return \"serenity\"\n",
    "            if topic == \"reflection\": return \"trust\" # Trust can be a calm, reflective mood\n",
    "            return \"neutral\"\n",
    "        if raw_emo_label == \"disgust\": # Model's 'disgust'\n",
    "            if emo_scores.get(\"sadness\",0) > 0.3: return \"remorse\"\n",
    "            return \"anger\" # Default map for disgust\n",
    "\n",
    "        # Fallback for any other model outputs or unmapped scenarios\n",
    "        return \"neutral\"\n",
    "\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        model_output = self.emoc(text[:512])[0] # Get all scores from the list\n",
    "        # Create a dictionary of scores for easier access\n",
    "        emo_scores_dict = {item['label'].lower(): item['score'] for item in model_output}\n",
    "        raw_emo_label = max(emo_scores_dict, key=emo_scores_dict.get) # Dominant raw emotion\n",
    "        \n",
    "        topic = self.zs_topic(text[:512], candidate_labels=self.topics)[\"labels\"][0].lower()\n",
    "        form_label  = self.zs_form(text[:512], candidate_labels=self.forms)[\"labels\"][0].lower()\n",
    "        \n",
    "        try:\n",
    "            self.tfidf.fit([text])\n",
    "            kws = list(self.tfidf.get_feature_names_out())\n",
    "        except: kws = []\n",
    "        \n",
    "        musical_mood_key = self._derive_musical_mood(raw_emo_label, emo_scores_dict, topic, kws)\n",
    "        mood_params = self.MUSICAL_MOOD_PARAMS.get(musical_mood_key, self.MUSICAL_MOOD_PARAMS[\"neutral\"])\n",
    "        \n",
    "        tmult = self.TOPIC_PARAMS.get(topic,1.0)\n",
    "        doc = self.nlp(text[:5000]) \n",
    "        ne_ratio  = len(doc.ents)/max(len(doc),1) if doc and len(doc) > 0 else 0\n",
    "        quotes    = len(re.findall(r'“[^”]+”', text))\n",
    "        num_sents = len(list(doc.sents)) if doc else 0\n",
    "        dlg_ratio = quotes/max(num_sents,1) if num_sents > 0 else 0\n",
    "        read     = textstat.flesch_reading_ease(text)\n",
    "        read_adj = int((read-60)/10)\n",
    "        \n",
    "        tempo = max(30, min(180, self.base_tempo + mood_params[\"tempo\"] + read_adj))\n",
    "        base_density_factor = tmult * (1 + dlg_ratio) \n",
    "        r_complex_factor = mood_params.get(\"r_complex\", 0.5)\n",
    "        # Adjust density to allow for very low values for long notes\n",
    "        density = np.clip(base_density_factor * (0.5 + r_complex_factor), 0.15, 4.0) \n",
    "\n",
    "        vol_lo_accomp, vol_hi_accomp = mood_params[\"vol\"]\n",
    "        mel_vol_adj = mood_params.get(\"mel_adj\", 0)\n",
    "        melody_specific_vol_range = (max(10, vol_lo_accomp + mel_vol_adj), max(20, vol_hi_accomp + mel_vol_adj))\n",
    "        accompaniment_base_vol_range = mood_params[\"vol\"]\n",
    "\n",
    "        melodic_range_hint = mood_params.get(\"mel_range\", (2,5)) \n",
    "        chord_progression_template = mood_params.get(\"prog\", [\"I\", \"IV\", \"V\", \"I\"])\n",
    "        dynamic_shape_hint = mood_params.get(\"dyn_shape\", \"flat\")\n",
    "        legato_intensity = mood_params.get(\"legato_i\", 0.85) \n",
    "        base_note_duration_multiplier = mood_params.get(\"base_dur_mult\", 1.0)\n",
    "\n",
    "        if \"is_major\" in mood_params: is_major_mode = mood_params[\"is_major\"]\n",
    "        else: is_major_mode = musical_mood_key in (\"joy\",\"surprise\",\"love\",\"neutral\",\"serenity\",\"trust\",\"awe\",\"optimism\")\n",
    "\n",
    "        mode_intervals = [0,2,4,5,7,9,11] if is_major_mode else [0,2,3,5,7,8,10]\n",
    "        shift = (sum(hash(k) for k in kws)+int(ne_ratio*12)) % 12 \n",
    "        melody_scale_notes = sorted([60 + i + shift for i in mode_intervals] + [72 + i + shift for i in mode_intervals])\n",
    "        harmony_base_octave = 48 \n",
    "        harmony_scale_root_notes = sorted([harmony_base_octave + i + shift for i in mode_intervals])\n",
    "\n",
    "        return (musical_mood_key, topic, form_label, melody_scale_notes, tempo, density, \n",
    "                melody_specific_vol_range, accompaniment_base_vol_range, melodic_range_hint,\n",
    "                chord_progression_template, harmony_scale_root_notes, is_major_mode, dynamic_shape_hint,\n",
    "                legato_intensity, base_note_duration_multiplier) # Now 15 params\n",
    "\n",
    "    # _get_velocity_for_shape, _select_next_note_index, _get_triad_notes, _map_roman_to_scale_degree\n",
    "    # (These remain largely the same as V3, minor tweaks if needed, e.g. _get_velocity_for_shape for new dyn_shapes)\n",
    "    def _get_velocity_for_shape(self, base_vol_range, progress_in_phrase, dynamic_shape_hint):\n",
    "        lo, hi = base_vol_range\n",
    "        span = hi - lo\n",
    "        vel = random.randint(lo, hi) # Default\n",
    "        \n",
    "        if dynamic_shape_hint == \"crescendo\" or dynamic_shape_hint == \"crescendo_slight\" or dynamic_shape_hint == \"crescendo_bright\":\n",
    "            vel = int(lo + span * progress_in_phrase)\n",
    "        elif dynamic_shape_hint == \"diminuendo\" or dynamic_shape_hint == \"diminuendo_slow\" or dynamic_shape_hint == \"diminuendo_heavy\":\n",
    "            vel = int(hi - span * progress_in_phrase)\n",
    "        elif dynamic_shape_hint == \"gentle_swell\" or dynamic_shape_hint == \"grand_swell\": \n",
    "            vel = int(lo + span * (0.5 + 0.5 * np.sin((progress_in_phrase - 0.5) * np.pi)))\n",
    "        elif dynamic_shape_hint == \"accented\": \n",
    "            vel = int(hi - span * progress_in_phrase * 0.7) if progress_in_phrase > 0.1 else hi\n",
    "        elif dynamic_shape_hint == \"sudden_loud\": \n",
    "            vel = hi if progress_in_phrase > 0.8 else int(lo + span * 0.2)\n",
    "        elif dynamic_shape_hint == \"subdued_var\": \n",
    "            vel = int(lo + span * (0.1 + 0.2 * np.sin(progress_in_phrase * 4 * np.pi)))\n",
    "        elif dynamic_shape_hint == \"very_flat_soft\":\n",
    "            vel = int(lo + span * 0.1) \n",
    "        elif dynamic_shape_hint == \"trembling\": \n",
    "            vel = int(lo + span * (0.1 + 0.1 * random.choice([-1,1,0,-0.5,0.5])))\n",
    "        elif dynamic_shape_hint == \"flat_warm\":\n",
    "            vel = int(lo + span * 0.4) # Consistently warm mid-volume\n",
    "        # else \"flat\" uses the random.randint default\n",
    "        return max(10, min(127, vel)) \n",
    "\n",
    "    def _select_next_note_index(self, current_note_idx, scale_len, melodic_range_hint, prev_step=0, tendency=0, mood_key=\"neutral\"):\n",
    "        min_jump, max_jump = melodic_range_hint\n",
    "        \n",
    "        possible_intervals = [-2, -1, 1, 2] \n",
    "        # For very smooth moods, mostly stepwise\n",
    "        if mood_key in [\"serenity\", \"sadness\", \"remorse\", \"pessimism\"]:\n",
    "            max_jump = min(max_jump, 2) # Limit jumps for these moods\n",
    "\n",
    "        for j in range(3, max_jump + 1):\n",
    "            if random.random() < 0.3 / (j+1e-6) : possible_intervals.extend([-j, j]) \n",
    "\n",
    "        weights = []\n",
    "        for interval in possible_intervals:\n",
    "            w = 1.0 / (abs(interval) + 0.1) \n",
    "            if abs(interval) > min_jump : w *= 0.4 # Stronger penalty for jumps\n",
    "            if abs(interval) == 1 and mood_key in [\"serenity\", \"sadness\", \"remorse\"]: w *= 2.0 # Favor stepwise for calm/sad\n",
    "            if interval == -prev_step and abs(prev_step) > 1: w*= 0.2 \n",
    "            if tendency != 0 and np.sign(interval) == tendency: w *= 1.5 \n",
    "            weights.append(max(0.01, w)) # Ensure weight is positive\n",
    "        \n",
    "        if not possible_intervals or not any(w > 0 for w in weights): \n",
    "             return (current_note_idx + 1) % scale_len, 1\n",
    "\n",
    "        chosen_step = random.choices(possible_intervals, weights=weights, k=1)[0]\n",
    "        next_idx = current_note_idx + chosen_step\n",
    "        next_idx = np.clip(next_idx, 0, scale_len - 1)\n",
    "        \n",
    "        if next_idx == current_note_idx and scale_len > 1:\n",
    "            # Try to move if stuck, respecting tendency if possible\n",
    "            if tendency > 0: chosen_step = 1\n",
    "            elif tendency < 0: chosen_step = -1\n",
    "            else: chosen_step = random.choice([-1,1])\n",
    "            next_idx = (current_note_idx + chosen_step + scale_len) % scale_len\n",
    "            \n",
    "        return int(next_idx), chosen_step\n",
    "\n",
    "    def _get_triad_notes(self, root_note_pitch, is_major_key, chord_type_str, scale_intervals, \n",
    "                         mood_key=\"neutral\", current_roman_numeral_in_prog=\"I\", root_degree_idx_for_chord=0):\n",
    "        # Allow mood to influence chord voicing slightly (e.g. add 7ths for some moods)\n",
    "        # Basic triads for now\n",
    "        third_interval = 4 if chord_type_str == \"M\" else 3 \n",
    "        if chord_type_str == \"A\": # Augmented\n",
    "            fifth_interval = 8\n",
    "        elif chord_type_str == \"d\": \n",
    "            fifth_interval = 6 \n",
    "        else: # Major or minor chord (perfect fifth)\n",
    "            fifth_interval = 7 \n",
    "        \n",
    "        notes = [root_note_pitch, root_note_pitch + third_interval, root_note_pitch + fifth_interval]\n",
    "        \n",
    "        # Simple 7th for specific moods/chords if desired\n",
    "        # For Imaj7 in Serenity/Love\n",
    "        if mood_key in [\"serenity\", \"love\"] and chord_type_str == \"M\" and \\\n",
    "           (\"maj7\" in current_roman_numeral_in_prog.lower() or (root_degree_idx_for_chord == 0 and random.random() < 0.4)): # I or Imaj7\n",
    "            notes.append(root_note_pitch + 11) # Major 7th\n",
    "\n",
    "        # For V7 (Dominant 7th)\n",
    "        elif chord_type_str == \"M\" and root_degree_idx_for_chord == 4 and \\\n",
    "             (\"7\" in current_roman_numeral_in_prog and \"maj7\" not in current_roman_numeral_in_prog.lower()): # If it's a V chord and \"7\" is in the roman numeral (but not maj7)\n",
    "            notes.append(root_note_pitch + 10) # Minor 7th for V7\n",
    "        \n",
    "        # For ii7 or other minor 7ths if specified or for suspense\n",
    "        elif chord_type_str == \"m\" and \\\n",
    "             (\"7\" in current_roman_numeral_in_prog or (mood_key == \"suspense\" and random.random() < 0.3)):\n",
    "            notes.append(root_note_pitch + 10) # Minor 7th\n",
    "\n",
    "        return [n for n in notes if 20 < n < 109]\n",
    "\n",
    "    def _map_roman_to_scale_degree(self, roman_numeral_str):\n",
    "        # ... (same as before, ensure it handles new suffixes from progressions)\n",
    "        cleaned_roman = roman_numeral_str.lower().replace(\"dim\",\"\").replace(\"o\",\"\").replace(\"aug\",\"\").replace(\"+\",\"\").replace(\"maj7\",\"\").replace(\"7sus\",\"\").replace(\"7\",\"\").replace(\"(add b6)\",\"\")\n",
    "        mapping = {\"i\":0, \"I\":0, \"ii\":1, \"II\":1, \"iii\":2, \"III\":2, \"iv\":3, \"IV\":3, \n",
    "                   \"v\":4, \"V\":4, \"vi\":5, \"VI\":5, \"vii\":6, \"VII\":6,\n",
    "                   \"bii\":1, \"bVI\":5, \"bVII\":6} # For Neapolitan, etc.\n",
    "        # Find the core Roman numeral part\n",
    "        core_match = re.match(r\"^(b?)([ivxIVX]+)\", cleaned_roman)\n",
    "        if core_match:\n",
    "            numeral_part = core_match.group(2)\n",
    "            degree = {\"i\":0,\"ii\":1,\"iii\":2,\"iv\":3,\"v\":4,\"vi\":5,\"vii\":6}.get(numeral_part,0)\n",
    "            # Basic handling for b (flat) modifiers, assumes it's a common flat like bII, bVI, bVII\n",
    "            # This simplified mapping may need adjustment for more complex theory\n",
    "            return degree\n",
    "        return 0 # Default\n",
    "\n",
    "\n",
    "    def _build_multi_track_music(self, musical_mood, topic, form, melody_scale_notes, tempo, density, \n",
    "                                 melody_vol_range, accompaniment_base_vol_range, \n",
    "                                 melodic_range_hint, chord_progression_template,\n",
    "                                 harmony_scale_root_notes, is_major_mode, dynamic_shape_hint,\n",
    "                                 legato_intensity, base_note_duration_multiplier): # Added base_note_duration_multiplier\n",
    "        # ... (initial setup from V3: mid, tracks, program changes, time_sig, tempo) ...\n",
    "        mid = mido.MidiFile(ticks_per_beat=self.tpb)\n",
    "        melody_track = mido.MidiTrack(); melody_track.name = \"Melody (Ch 0)\"; mid.tracks.append(melody_track)\n",
    "        bass_track = mido.MidiTrack(); bass_track.name = \"Bass (Ch 1)\"; mid.tracks.append(bass_track)\n",
    "        chord_track = mido.MidiTrack(); chord_track.name = \"Chords (Ch 2)\"; mid.tracks.append(chord_track)\n",
    "\n",
    "        melody_track.append(mido.Message('program_change', channel=0, program=0, time=0)) # Piano\n",
    "        # Consider changing instruments based on mood\n",
    "        if musical_mood in [\"serenity\", \"awe\"]:\n",
    "            chord_track.append(mido.Message('program_change', channel=2, program=52, time=0)) # Choir Aahs / Synth Voice\n",
    "        elif musical_mood == \"suspense\":\n",
    "             chord_track.append(mido.Message('program_change', channel=2, program=99, time=0)) # FX 3 (crystal) or 50 (Synth Strings 1)\n",
    "        else:\n",
    "            chord_track.append(mido.Message('program_change', channel=2, program=48, time=0)) # Strings\n",
    "        bass_track.append(mido.Message('program_change', channel=1, program=33, time=0))\n",
    "\n",
    "\n",
    "        is_waltz = (form == \"waltz\")\n",
    "        beats_per_measure = 3 if is_waltz else 4\n",
    "        current_tick_abs = 0 \n",
    "        melody_track.append(mido.MetaMessage('time_signature', numerator=beats_per_measure, denominator=4, time=0))\n",
    "        melody_track.append(mido.MetaMessage('set_tempo', tempo=mido.bpm2tempo(tempo), time=0))\n",
    "\n",
    "        if not melody_scale_notes: melody_scale_notes = [60, 62, 64, 65, 67, 69, 71, 72, 74, 76, 77, 79, 81, 83] \n",
    "        melody_scale_len = len(melody_scale_notes)\n",
    "        current_melody_note_idx = random.randint(melody_scale_len // 4, melody_scale_len // 2) \n",
    "        prev_melody_step = 0 \n",
    "\n",
    "        # Apply base_note_duration_multiplier to the average slot duration\n",
    "        avg_rhythmic_slot_duration_ticks = (self.tpb / density) * base_note_duration_multiplier\n",
    "        # Ensure it's not excessively small\n",
    "        avg_rhythmic_slot_duration_ticks = max(self.tpb / 8, avg_rhythmic_slot_duration_ticks) # at least a 32nd note for base if tpb=480\n",
    "\n",
    "        rhythmic_patterns = {\n",
    "            \"simple\": [1.0], \"long_focus\": [2.0, 1.0, 1.0] if base_note_duration_multiplier >=1.5 else [1.0], # if base is already long, keep it simple\n",
    "            \"varied1\": [1.5, 0.5], \"varied2\": [0.75, 0.25, 1.0],\"dotted\": [0.75,0.25],\n",
    "            \"sparse\": [2.0, 2.0] if base_note_duration_multiplier >=1.5 else [1.0,1.0,2.0], # For very slow moods\n",
    "            \"even_flow\": [0.5, 0.5] if density * base_note_duration_multiplier >=1.0 else [1.0] \n",
    "        }\n",
    "        if musical_mood in [\"serenity\", \"sadness\", \"pessimism\", \"remorse\"]: chosen_rhythm_key_default = \"sparse\"\n",
    "        elif musical_mood == \"suspense\": chosen_rhythm_key_default = \"long_focus\"\n",
    "        else: chosen_rhythm_key_default = \"simple\"\n",
    "        \n",
    "        bass_vol_range = (max(20, int(accompaniment_base_vol_range[0]*0.7)), max(30,int(accompaniment_base_vol_range[1]*0.8)))\n",
    "        chord_vol_range = (max(20, int(accompaniment_base_vol_range[0]*0.6)), max(30,int(accompaniment_base_vol_range[1]*0.75)))\n",
    "        \n",
    "        # Global prog_idx needs to be accessible by _get_triad_notes if it uses it for V7 detection\n",
    "        # It's better to pass prog_idx or the current roman numeral to _get_triad_notes\n",
    "        self.prog_idx_global = 0 # Use self if need to access in helper without passing\n",
    "\n",
    "        key_diatonic_qualities = self.MAJOR_DIATONIC_CHORDS if is_major_mode else self.MINOR_DIATONIC_CHORDS\n",
    "        scale_intervals_for_chords = [0,2,4,5,7,9,11] if is_major_mode else [0,2,3,5,7,8,10]\n",
    "        track_event_times = {\"melody\": 0, \"bass\": 0, \"chords\": 0}\n",
    "\n",
    "        def add_message_to_track(track_obj, track_name_key, msg_type, target_abs_tick, **kwargs):\n",
    "            delta_t = target_abs_tick - track_event_times[track_name_key]\n",
    "            if delta_t < 0: delta_t = 0 \n",
    "            msg_kwargs = kwargs.copy(); msg_kwargs['time'] = int(delta_t) \n",
    "            track_obj.append(mido.Message(msg_type, **msg_kwargs))\n",
    "            track_event_times[track_name_key] = target_abs_tick\n",
    "        \n",
    "        def add_note_sequence(track_obj, track_name_key, channel, notes, velocity, start_abs_tick, \n",
    "                              rhythmic_duration_ticks, sounding_duration_factor=1.0):\n",
    "            # For piano legato, sounding_duration might slightly exceed rhythmic_duration\n",
    "            # Let legato_factor be 0-1 for how much of the slot it fills,\n",
    "            # And an additional small overlap for >1.0 for true legato simulation\n",
    "            overlap_ticks = 0\n",
    "            if channel == 0 and sounding_duration_factor > 0.95: # Melody piano\n",
    "                # if sounding_duration_factor near 1.0, make it fill the slot\n",
    "                # if > 1.0, it means overlap\n",
    "                overlap_factor = sounding_duration_factor # Use the direct factor\n",
    "                # Calculate overlap: if factor is 1.05, it means 5% overlap\n",
    "                # The note_off happens *after* the rhythmic slot by a small amount\n",
    "                effective_sounding_duration = int(rhythmic_duration_ticks * overlap_factor)\n",
    "            else: # Accompaniment, less critical for overlap\n",
    "                effective_sounding_duration = int(rhythmic_duration_ticks * min(sounding_duration_factor, 1.0)) # Cap at 1.0 for accompaniment\n",
    "\n",
    "            effective_sounding_duration = max(self.tpb // 16, effective_sounding_duration)\n",
    "\n",
    "            for note_pitch in notes: \n",
    "                add_message_to_track(track_obj, track_name_key, 'note_on', start_abs_tick, channel=channel, note=note_pitch, velocity=int(velocity))\n",
    "            for note_pitch in notes:\n",
    "                add_message_to_track(track_obj, track_name_key, 'note_off', start_abs_tick + effective_sounding_duration, channel=channel, note=note_pitch, velocity=0)\n",
    "\n",
    "        for cycle_num in range(self.cycles):\n",
    "            num_measures_per_cycle = random.choice([2,3,4]) if form not in [\"etude\", \"prelude\"] else 2\n",
    "            phrase_tendency = random.choice([-1,0,1]) if musical_mood not in [\"sadness\",\"fear\",\"serenity\",\"suspense\",\"pessimism\",\"remorse\"] else random.choice([-1,-1,0]) \n",
    "\n",
    "            for measure_num_in_cycle in range(num_measures_per_cycle):\n",
    "                measure_start_abs_tick = current_tick_abs\n",
    "                ticks_in_measure = beats_per_measure * self.tpb\n",
    "                \n",
    "                current_roman_numeral = chord_progression_template[self.prog_idx_global % len(chord_progression_template)]\n",
    "                chord_type_override = None\n",
    "                if \"aug\" in current_roman_numeral.lower() or \"+\" in current_roman_numeral: chord_type_override = \"A\"\n",
    "                elif \"dim\" in current_roman_numeral.lower() or \"o\" in current_roman_numeral: chord_type_override = \"d\"\n",
    "\n",
    "                root_degree_idx = self._map_roman_to_scale_degree(current_roman_numeral)\n",
    "                chord_root_pitch = harmony_scale_root_notes[root_degree_idx % len(harmony_scale_root_notes)]\n",
    "                chord_type = chord_type_override if chord_type_override else key_diatonic_qualities[root_degree_idx % len(key_diatonic_qualities)]\n",
    "                \n",
    "                # Pass current_roman_numeral or prog_idx to _get_triad_notes if it needs it for V7 etc.\n",
    "                # For now, it's not used in _get_triad_notes for V7 detection logic (that part was commented out).\n",
    "                triad_pitches = self._get_triad_notes(chord_root_pitch, is_major_mode, chord_type, scale_intervals_for_chords, musical_mood)\n",
    "                self.prog_idx_global +=1\n",
    "                \n",
    "                # --- Accompaniment Tracks (Bass & Chords) ---\n",
    "                bass_vel = self._get_velocity_for_shape(bass_vol_range, (measure_num_in_cycle + 0.5) / num_measures_per_cycle, dynamic_shape_hint)\n",
    "                chord_vel = self._get_velocity_for_shape(chord_vol_range, (measure_num_in_cycle + 0.5) / num_measures_per_cycle, dynamic_shape_hint)\n",
    "\n",
    "                if form == \"waltz\":\n",
    "                    add_note_sequence(bass_track, \"bass\", 1, [chord_root_pitch], bass_vel, measure_start_abs_tick, self.tpb, sounding_duration_factor=0.9) # Bass slightly staccato\n",
    "                    add_note_sequence(chord_track, \"chords\", 2, triad_pitches, chord_vel, measure_start_abs_tick + self.tpb, self.tpb, sounding_duration_factor=0.8)\n",
    "                    add_note_sequence(chord_track, \"chords\", 2, triad_pitches, chord_vel, measure_start_abs_tick + self.tpb*2, self.tpb, sounding_duration_factor=0.8)\n",
    "                else: # Other forms\n",
    "                    bass_sounding_factor = 0.95 if musical_mood not in [\"serenity\", \"sadness\"] else 1.0 # Longer bass for slow moods\n",
    "                    add_note_sequence(bass_track, \"bass\", 1, [chord_root_pitch], bass_vel, measure_start_abs_tick, ticks_in_measure, sounding_duration_factor=bass_sounding_factor) # Bass holds longer\n",
    "\n",
    "                    chord_legato = 0.95 if musical_mood in [\"serenity\", \"sadness\", \"awe\"] else 0.9 \n",
    "                    if form == \"prelude\" and random.random() > 0.3: \n",
    "                        # ... (arpeggio logic - simplified, ensure it uses add_note_sequence correctly) ...\n",
    "                        arp_note_dur = self.tpb // (2 if density > 1 else 1) \n",
    "                        current_arp_tick = measure_start_abs_tick\n",
    "                        safe_triad = [p for p in triad_pitches if 20<p<109] or [60]\n",
    "                        for note in safe_triad + [safe_triad[1%len(safe_triad)]]:\n",
    "                             if current_arp_tick >= measure_start_abs_tick + ticks_in_measure: break\n",
    "                             actual_arp_dur = min(arp_note_dur, (measure_start_abs_tick + ticks_in_measure) - current_arp_tick)\n",
    "                             if actual_arp_dur <=0 : break\n",
    "                             add_note_sequence(chord_track, \"chords\", 2, [note], int(chord_vel*0.8), current_arp_tick, actual_arp_dur, sounding_duration_factor=0.98)\n",
    "                             current_arp_tick += actual_arp_dur\n",
    "                    else: \n",
    "                        add_note_sequence(chord_track, \"chords\", 2, triad_pitches, chord_vel, measure_start_abs_tick, ticks_in_measure, sounding_duration_factor=chord_legato)\n",
    "                \n",
    "                # --- Melody Track ---\n",
    "                current_melody_ticks_in_measure = 0\n",
    "                # Choose rhythm pattern based on mood\n",
    "                if musical_mood in rhythmic_patterns: chosen_rhythm_key = musical_mood # if specific pattern for mood\n",
    "                else: chosen_rhythm_key = chosen_rhythm_key_default if chosen_rhythm_key_default in rhythmic_patterns else random.choice(list(rhythmic_patterns.keys()))\n",
    "                \n",
    "                _avg_slot_for_melody = avg_rhythmic_slot_duration_ticks # This already includes base_dur_mult\n",
    "                current_rhythmic_pattern_melody = list(rhythmic_patterns[chosen_rhythm_key])\n",
    "                if form == \"etude\": \n",
    "                    _avg_slot_for_melody = (self.tpb / max(1.0, density * 1.8)) * base_note_duration_multiplier # Etudes faster but respect base_dur_mult\n",
    "                    current_rhythmic_pattern_melody = [0.5, 0.5] \n",
    "                \n",
    "                rhythm_idx = 0\n",
    "                while current_melody_ticks_in_measure < ticks_in_measure:\n",
    "                    # ... (progress calculations) ...\n",
    "                    progress_in_measure = current_melody_ticks_in_measure / ticks_in_measure if ticks_in_measure > 0 else 0\n",
    "                    progress_in_phrase = (measure_num_in_cycle + progress_in_measure) / num_measures_per_cycle if num_measures_per_cycle > 0 else 0\n",
    "\n",
    "                    duration_factor = current_rhythmic_pattern_melody[rhythm_idx % len(current_rhythmic_pattern_melody)]\n",
    "                    rhythmic_slot_duration = int(_avg_slot_for_melody * duration_factor)\n",
    "                    rhythmic_slot_duration = max(self.tpb // 8, rhythmic_slot_duration) # Min 32nd note slot\n",
    "                    \n",
    "                    if current_melody_ticks_in_measure + rhythmic_slot_duration > ticks_in_measure:\n",
    "                        rhythmic_slot_duration = ticks_in_measure - current_melody_ticks_in_measure\n",
    "                    if rhythmic_slot_duration <= self.tpb // 32 : break \n",
    "\n",
    "                    current_melody_note_idx, prev_melody_step = self._select_next_note_index(\n",
    "                        current_melody_note_idx, melody_scale_len, melodic_range_hint, prev_melody_step, phrase_tendency, musical_mood\n",
    "                    )\n",
    "                    note_pitch = melody_scale_notes[current_melody_note_idx]\n",
    "                    mel_vel = self._get_velocity_for_shape(melody_vol_range, progress_in_phrase, dynamic_shape_hint)\n",
    "                    \n",
    "                    add_note_sequence(melody_track, \"melody\", 0, [note_pitch], mel_vel, \n",
    "                                      measure_start_abs_tick + current_melody_ticks_in_measure, \n",
    "                                      rhythmic_slot_duration, \n",
    "                                      sounding_duration_factor=legato_intensity) # Use legato_intensity\n",
    "                    \n",
    "                    current_melody_ticks_in_measure += rhythmic_slot_duration\n",
    "                    rhythm_idx += 1\n",
    "                current_tick_abs += ticks_in_measure \n",
    "        return mid\n",
    "\n",
    "    def text_to_midi(self, text, out_path, form_override=None, emotion_override=None):\n",
    "        # This method needs to unpack 15 values from analyze_text\n",
    "        # And pass all 15 to _build_multi_track_music in the correct order\n",
    "        if not text or len(text.strip()) < 10:\n",
    "            text = \"Neutral placeholder text for music generation due to short input.\"\n",
    "            print(f\"Warning: Input text for {out_path} was too short. Using placeholder.\")\n",
    "\n",
    "        (analyzed_mood_val, analyzed_topic_val, analyzed_form_val, \n",
    "         analyzed_melody_scale_val, analyzed_tempo_val, analyzed_density_val, \n",
    "         analyzed_melody_specific_vr_val, analyzed_accompaniment_base_vr_val, \n",
    "         analyzed_mrh_val, analyzed_prog_val, analyzed_harmony_scale_val, \n",
    "         analyzed_is_major_val, analyzed_dynamic_shape_val,\n",
    "         analyzed_legato_intensity_val, analyzed_base_dur_mult_val # New\n",
    "         ) = self.analyze_text(text) # Ensure 15 values are returned and unpacked\n",
    "        \n",
    "        final_form = form_override or analyzed_form_val\n",
    "        final_mood  = emotion_override or analyzed_mood_val \n",
    "        \n",
    "        # Initialize final values\n",
    "        final_tempo = analyzed_tempo_val\n",
    "        final_density = analyzed_density_val\n",
    "        final_melody_vr = analyzed_melody_specific_vr_val\n",
    "        final_accomp_vr = analyzed_accompaniment_base_vr_val\n",
    "        final_mrh = analyzed_mrh_val\n",
    "        final_melody_scale = analyzed_melody_scale_val\n",
    "        final_prog = analyzed_prog_val\n",
    "        final_harmony_scale = analyzed_harmony_scale_val\n",
    "        final_is_major = analyzed_is_major_val\n",
    "        final_dynamic_shape = analyzed_dynamic_shape_val\n",
    "        final_legato_intensity = analyzed_legato_intensity_val\n",
    "        final_base_dur_mult = analyzed_base_dur_mult_val\n",
    "\n",
    "        if emotion_override: # If final_mood is based on override\n",
    "            mood_params = self.MUSICAL_MOOD_PARAMS.get(final_mood, self.MUSICAL_MOOD_PARAMS[\"neutral\"])\n",
    "            original_mood_for_recalc = analyzed_mood_val # Mood derived from text\n",
    "            original_mood_params_for_recalc = self.MUSICAL_MOOD_PARAMS.get(original_mood_for_recalc, self.MUSICAL_MOOD_PARAMS[\"neutral\"])\n",
    "\n",
    "            read_adj_approx = analyzed_tempo_val - self.base_tempo - original_mood_params_for_recalc[\"tempo\"] \n",
    "            final_tempo = max(30, min(180, self.base_tempo + mood_params[\"tempo\"] + read_adj_approx))\n",
    "            \n",
    "            vol_lo, vol_hi = mood_params[\"vol\"]\n",
    "            mel_vol_adj = mood_params.get(\"mel_adj\",0)\n",
    "            final_melody_vr = (max(10, vol_lo + mel_vol_adj), max(20, vol_hi + mel_vol_adj))\n",
    "            final_accomp_vr = mood_params[\"vol\"]\n",
    "\n",
    "            final_mrh = mood_params.get(\"mel_range\", (2,5))\n",
    "            final_prog = mood_params.get(\"prog\", [\"I\", \"IV\", \"V\", \"I\"])\n",
    "            final_dynamic_shape = mood_params.get(\"dyn_shape\", \"flat\")\n",
    "            final_legato_intensity = mood_params.get(\"legato_i\", 0.85)\n",
    "            final_base_dur_mult = mood_params.get(\"base_dur_mult\", 1.0)\n",
    "            \n",
    "            if \"is_major\" in mood_params: final_is_major = mood_params[\"is_major\"]\n",
    "            else: final_is_major = final_mood in (\"joy\",\"surprise\",\"love\",\"neutral\",\"serenity\",\"trust\",\"awe\",\"optimism\")\n",
    "            \n",
    "            original_base_density_approx = analyzed_density_val / (0.5 + original_mood_params_for_recalc.get(\"r_complex\", 0.5) + 1e-6) # Adjusted denominator\n",
    "            new_r_complex_factor = mood_params.get(\"r_complex\", 0.5)\n",
    "            final_density = np.clip(original_base_density_approx * (0.5 + new_r_complex_factor), 0.15, 4.0)\n",
    "\n",
    "            new_mode_intervals = [0,2,4,5,7,9,11] if final_is_major else [0,2,3,5,7,8,10]\n",
    "            original_is_major_for_shift = self.MUSICAL_MOOD_PARAMS.get(original_mood_for_recalc,{}).get(\"is_major\", original_mood_for_recalc in (\"joy\",\"surprise\",\"love\",\"neutral\",\"serenity\",\"trust\",\"awe\",\"optimism\"))\n",
    "            original_mode_intervals_for_shift = [0,2,4,5,7,9,11] if original_is_major_for_shift else [0,2,3,5,7,8,10]\n",
    "            \n",
    "            if analyzed_melody_scale_val and original_mode_intervals_for_shift:\n",
    "                original_shift_val = (analyzed_melody_scale_val[0] - 60 - original_mode_intervals_for_shift[0]) % 12\n",
    "            else: original_shift_val = 0 \n",
    "            \n",
    "            final_melody_scale = sorted([60 + i + original_shift_val for i in new_mode_intervals] + [72 + i + original_shift_val for i in new_mode_intervals])\n",
    "            harmony_base_octave = 48\n",
    "            final_harmony_scale = sorted([harmony_base_octave + i + original_shift_val for i in new_mode_intervals])\n",
    "\n",
    "        print(f\"Generating Multi-Track V4: Mood={final_mood}, Form={final_form}, Tempo={final_tempo}, Legato={final_legato_intensity:.2f}, BaseDurM={final_base_dur_mult:.2f}\")\n",
    "\n",
    "        midi_obj = self._build_multi_track_music(\n",
    "            final_mood, analyzed_topic_val, final_form, final_melody_scale, final_tempo, \n",
    "            final_density, final_melody_vr, final_accomp_vr, final_mrh, \n",
    "            final_prog, final_harmony_scale, final_is_major,\n",
    "            final_dynamic_shape, final_legato_intensity, final_base_dur_mult # Pass all 15\n",
    "        )\n",
    "        \n",
    "        midi_obj.save(out_path)\n",
    "        print(f\"▶️ Saved Multi-Track V4: {out_path} [{final_mood}/{analyzed_topic_val}/{final_form} @ {final_tempo} BPM]\")\n",
    "\n",
    "\n",
    "# --- extract_feats and rule_emotion functions as before ---\n",
    "# ... (copy from your working version) ...\n",
    "def extract_feats(path):\n",
    "    try:\n",
    "        mid = mido.MidiFile(str(path), clip=True)\n",
    "    except Exception: \n",
    "        return None\n",
    "    notes, vels, tempos_val = [], [], []\n",
    "    tpb = mid.ticks_per_beat if mid.ticks_per_beat > 0 else 480 \n",
    "    ticks_total=0\n",
    "    first_tempo_us = None\n",
    "\n",
    "    for tr_idx, tr in enumerate(mid.tracks):\n",
    "        current_time_in_track = 0\n",
    "        for msg_idx, msg in enumerate(tr):\n",
    "            current_time_in_track += msg.time\n",
    "            if msg.type==\"set_tempo\": \n",
    "                tempos_val.append(msg.tempo)\n",
    "                if first_tempo_us is None: \n",
    "                    first_tempo_us = msg.tempo\n",
    "            elif msg.type==\"note_on\" and msg.velocity>0:\n",
    "                notes.append(msg.note); vels.append(msg.velocity)\n",
    "        ticks_total = max(ticks_total, current_time_in_track)\n",
    "\n",
    "    if not tempos_val and first_tempo_us is None: \n",
    "        tempo_us = 500000 \n",
    "    elif first_tempo_us is not None:\n",
    "        tempo_us = first_tempo_us\n",
    "    else: \n",
    "        tempo_us = tempos_val[0]\n",
    "\n",
    "    bpm = mido.tempo2bpm(tempo_us) if tempo_us > 0 else 120\n",
    "    dyn_mean = float(np.mean(vels)) if vels else 64.0\n",
    "    secs = mido.tick2second(ticks_total, tpb, tempo_us) if tpb > 0 and tempo_us > 0 else 0\n",
    "    density_feat  = len(notes)/secs if secs > 0 else 0.0 \n",
    "    prange   = (max(notes)-min(notes)) if len(notes) > 1 else 0 \n",
    "    return np.array([bpm,dyn_mean,density_feat,prange])\n",
    "\n",
    "def rule_emotion(feats):\n",
    "    if feats is None: return \"neutral\"\n",
    "    bpm,dyn,dens,pr=feats\n",
    "    # These labels should ideally match keys in MUSICAL_MOOD_PARAMS or be mapped by _derive_musical_mood\n",
    "    if bpm>125 and dyn>65 and dens > 2.5: return \"joy\" \n",
    "    if bpm<85 and dens < 2.5 and dyn < 60: return \"sadness\" \n",
    "    if dens<2.0 and bpm < 105 and dyn < 70 : return \"neutral\" # Was \"calm\", map to neutral or serenity\n",
    "    if bpm > 110 and dyn > 60 and dens > 2.0 : return \"joy\" # Was \"energetic\", map to joy or anticipation\n",
    "    return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a3b031",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m X,y = [],[]\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m subset:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     feats = \u001b[43mextract_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     34\u001b[39m     X.append(feats); y.append(rule_emotion(feats))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 523\u001b[39m, in \u001b[36mextract_feats\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_feats\u001b[39m(path):\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m         mid = \u001b[43mmido\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMidiFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m: \n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jenny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mido\\midifiles\\midifiles.py:320\u001b[39m, in \u001b[36mMidiFile.__init__\u001b[39m\u001b[34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jenny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mido\\midifiles\\midifiles.py:371\u001b[39m, in \u001b[36mMidiFile._load\u001b[39m\u001b[34m(self, infile)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug:\n\u001b[32m    369\u001b[39m     _dbg(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTrack \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m \u001b[38;5;28mself\u001b[39m.tracks.append(\u001b[43mread_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jenny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mido\\midifiles\\midifiles.py:187\u001b[39m, in \u001b[36mread_track\u001b[39m\u001b[34m(infile, debug, clip)\u001b[39m\n\u001b[32m    183\u001b[39m last_status = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# End of track reached.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m - start == size:\n\u001b[32m    188\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 2: clean folders + classify Maestro forms & LMD emotions\n",
    "import shutil, os, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 1) clear old splits\n",
    "for d in [\"data/maestro_subset\",\"data/lmd_emotion\"]:\n",
    "    if os.path.isdir(d): shutil.rmtree(d)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# 2) Maestro → forms (via CSV)\n",
    "CSV = Path(\"data/maestro/maestro-v3.0.0/maestro-v3.0.0.csv\")\n",
    "MAE = Path(\"data/maestro/maestro-v3.0.0\")\n",
    "OUT = Path(\"data/maestro_subset\")\n",
    "FORMS = [\"sonata\",\"etude\",\"prelude\",\"waltz\",\"nocturne\"]\n",
    "df = pd.read_csv(CSV)\n",
    "for _,r in df.iterrows():\n",
    "    f = next((x for x in FORMS if x in str(r.canonical_title).lower()), None)\n",
    "    if not f: continue\n",
    "    src = MAE / r.midi_filename\n",
    "    if src.exists():\n",
    "        dst = OUT/f/src.name\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(src,dst)\n",
    "\n",
    "# 3) LMD → emotions (fast RF on a 500‐file subset)\n",
    "all_mid = glob.glob(\"data/lmd_clean/**/*.mid\", recursive=True)\n",
    "subset = random.sample(all_mid, min(500,len(all_mid)))\n",
    "X,y = [],[]\n",
    "for fn in subset:\n",
    "    feats = extract_feats(fn)\n",
    "    if feats is None: continue\n",
    "    X.append(feats); y.append(rule_emotion(feats))\n",
    "X = np.stack(X)\n",
    "le = LabelEncoder().fit(y)\n",
    "y_enc = le.transform(y)\n",
    "clf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "print(\"CV emo‐acc:\", np.mean(cross_val_score(clf,X,y_enc,cv=3)))\n",
    "clf.fit(X,y_enc)\n",
    "os.makedirs(\"models\",exist_ok=True)\n",
    "pickle.dump((le,clf), open(\"models/lmd_emotion_clf.pkl\",\"wb\"))\n",
    "\n",
    "# 4) apply RF to all LMD MIDI\n",
    "OUT2 = Path(\"data/lmd_emotion\")\n",
    "for fn in glob.glob(\"data/lmd_clean/**/*.mid\", recursive=True):\n",
    "    feats = extract_feats(fn)\n",
    "    if feats is None: continue\n",
    "    emo = le.inverse_transform([clf.predict(feats.reshape(1,-1))[0]])[0]\n",
    "    dst = OUT2/emo/Path(fn).name\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(fn,dst)\n",
    "\n",
    "print(\"✅ Maestro & LMD re‐classified fresh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing book: aliceinwonderland.txt\n",
      "Detected Chapter structure.\n",
      "  Generating for: ChapI\n",
      "Generating Multi-Track V3: Mood=neutral, Form=fugue, Tempo=80, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapI_fugue_neutral.mid [neutral/tension/fugue @ 80 BPM]\n",
      "    → aliceinwonderland_ChapI_fugue_neutral.mid\n",
      "  Generating for: ChapII\n",
      "Generating Multi-Track V3: Mood=sadness, Form=etude, Tempo=60, DynShape=diminuendo, LegatoF=0.98\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapII_etude_sadness.mid [sadness/violence/etude @ 60 BPM]\n",
      "    → aliceinwonderland_ChapII_etude_sadness.mid\n",
      "  Generating for: ChapIII\n",
      "Generating Multi-Track V3: Mood=neutral, Form=prelude, Tempo=82, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapIII_prelude_neutral.mid [neutral/tension/prelude @ 82 BPM]\n",
      "    → aliceinwonderland_ChapIII_prelude_neutral.mid\n",
      "  Generating for: ChapIV\n",
      "Generating Multi-Track V3: Mood=sadness, Form=etude, Tempo=58, DynShape=diminuendo, LegatoF=0.98\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapIV_etude_sadness.mid [sadness/family/etude @ 58 BPM]\n",
      "    → aliceinwonderland_ChapIV_etude_sadness.mid\n",
      "  Generating for: ChapV\n",
      "Generating Multi-Track V3: Mood=neutral, Form=etude, Tempo=78, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapV_etude_neutral.mid [neutral/tension/etude @ 78 BPM]\n",
      "    → aliceinwonderland_ChapV_etude_neutral.mid\n",
      "  Generating for: ChapVI\n",
      "Generating Multi-Track V3: Mood=neutral, Form=etude, Tempo=83, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapVI_etude_neutral.mid [neutral/violence/etude @ 83 BPM]\n",
      "    → aliceinwonderland_ChapVI_etude_neutral.mid\n",
      "  Generating for: ChapVII\n",
      "Generating Multi-Track V3: Mood=joy, Form=fantasy, Tempo=103, DynShape=crescendo, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapVII_fantasy_joy.mid [joy/tension/fantasy @ 103 BPM]\n",
      "    → aliceinwonderland_ChapVII_fantasy_joy.mid\n",
      "  Generating for: ChapVIII\n",
      "Generating Multi-Track V3: Mood=anger, Form=etude, Tempo=90, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapVIII_etude_anger.mid [anger/tension/etude @ 90 BPM]\n",
      "    → aliceinwonderland_ChapVIII_etude_anger.mid\n",
      "  Generating for: ChapIX\n",
      "Generating Multi-Track V3: Mood=neutral, Form=etude, Tempo=81, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapIX_etude_neutral.mid [neutral/mystery/etude @ 81 BPM]\n",
      "    → aliceinwonderland_ChapIX_etude_neutral.mid\n",
      "  Generating for: ChapX\n",
      "Generating Multi-Track V3: Mood=neutral, Form=ballad, Tempo=83, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapX_ballad_neutral.mid [neutral/tension/ballad @ 83 BPM]\n",
      "    → aliceinwonderland_ChapX_ballad_neutral.mid\n",
      "  Generating for: ChapXI\n",
      "Generating Multi-Track V3: Mood=neutral, Form=etude, Tempo=85, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapXI_etude_neutral.mid [neutral/mystery/etude @ 85 BPM]\n",
      "    → aliceinwonderland_ChapXI_etude_neutral.mid\n",
      "  Generating for: ChapXII\n",
      "Generating Multi-Track V3: Mood=neutral, Form=etude, Tempo=70, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapXII_etude_neutral.mid [neutral/tension/etude @ 70 BPM]\n",
      "    → aliceinwonderland_ChapXII_etude_neutral.mid\n",
      "  Generating for: ChapI\n",
      "Generating Multi-Track V3: Mood=sadness, Form=prelude, Tempo=56, DynShape=diminuendo, LegatoF=0.98\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapI_prelude_sadness.mid [sadness/family/prelude @ 56 BPM]\n",
      "    → aliceinwonderland_ChapI_prelude_sadness.mid\n",
      "  Generating for: ChapII\n",
      "Generating Multi-Track V3: Mood=surprise, Form=etude, Tempo=97, DynShape=sudden_loud, LegatoF=0.75\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapII_etude_surprise.mid [surprise/mystery/etude @ 97 BPM]\n",
      "    → aliceinwonderland_ChapII_etude_surprise.mid\n",
      "  Generating for: ChapIII\n",
      "Generating Multi-Track V3: Mood=anger, Form=prelude, Tempo=91, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapIII_prelude_anger.mid [anger/tension/prelude @ 91 BPM]\n",
      "    → aliceinwonderland_ChapIII_prelude_anger.mid\n",
      "  Generating for: ChapIV\n",
      "Generating Multi-Track V3: Mood=surprise, Form=etude, Tempo=96, DynShape=sudden_loud, LegatoF=0.75\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapIV_etude_surprise.mid [surprise/mystery/etude @ 96 BPM]\n",
      "    → aliceinwonderland_ChapIV_etude_surprise.mid\n",
      "  Generating for: ChapV\n",
      "Generating Multi-Track V3: Mood=suspense, Form=prelude, Tempo=66, DynShape=trembling, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapV_prelude_suspense.mid [suspense/mystery/prelude @ 66 BPM]\n",
      "    → aliceinwonderland_ChapV_prelude_suspense.mid\n",
      "  Generating for: ChapVI\n",
      "Generating Multi-Track V3: Mood=anger, Form=etude, Tempo=91, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapVI_etude_anger.mid [anger/mystery/etude @ 91 BPM]\n",
      "    → aliceinwonderland_ChapVI_etude_anger.mid\n",
      "  Generating for: ChapVII\n",
      "Generating Multi-Track V3: Mood=anger, Form=etude, Tempo=92, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapVII_etude_anger.mid [anger/tension/etude @ 92 BPM]\n",
      "    → aliceinwonderland_ChapVII_etude_anger.mid\n",
      "  Generating for: ChapVIII\n",
      "Generating Multi-Track V3: Mood=anger, Form=prelude, Tempo=91, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapVIII_prelude_anger.mid [anger/mystery/prelude @ 91 BPM]\n",
      "    → aliceinwonderland_ChapVIII_prelude_anger.mid\n",
      "  Generating for: ChapIX\n",
      "Generating Multi-Track V3: Mood=joy, Form=etude, Tempo=102, DynShape=crescendo, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapIX_etude_joy.mid [joy/violence/etude @ 102 BPM]\n",
      "    → aliceinwonderland_ChapIX_etude_joy.mid\n",
      "  Generating for: ChapX\n",
      "Generating Multi-Track V3: Mood=fear, Form=prelude, Tempo=77, DynShape=subdued_var, LegatoF=0.90\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapX_prelude_fear.mid [fear/violence/prelude @ 77 BPM]\n",
      "    → aliceinwonderland_ChapX_prelude_fear.mid\n",
      "  Generating for: ChapXI\n",
      "Generating Multi-Track V3: Mood=anger, Form=etude, Tempo=92, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapXI_etude_anger.mid [anger/mystery/etude @ 92 BPM]\n",
      "    → aliceinwonderland_ChapXI_etude_anger.mid\n",
      "  Generating for: ChapXII\n",
      "Generating Multi-Track V3: Mood=surprise, Form=etude, Tempo=95, DynShape=sudden_loud, LegatoF=0.75\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\aliceinwonderland\\aliceinwonderland_ChapXII_etude_surprise.mid [surprise/violence/etude @ 95 BPM]\n",
      "    → aliceinwonderland_ChapXII_etude_surprise.mid\n",
      "\n",
      "Processing book: frankenstein.txt\n",
      "Detected Chapter structure.\n",
      "  Generating for: Chap1\n",
      "    Skipping empty segment: Chap1\n",
      "  Generating for: Chap2\n",
      "    Skipping empty segment: Chap2\n",
      "  Generating for: Chap3\n",
      "    Skipping empty segment: Chap3\n",
      "  Generating for: Chap4\n",
      "    Skipping empty segment: Chap4\n",
      "  Generating for: Chap5\n",
      "    Skipping empty segment: Chap5\n",
      "  Generating for: Chap6\n",
      "    Skipping empty segment: Chap6\n",
      "  Generating for: Chap7\n",
      "    Skipping empty segment: Chap7\n",
      "  Generating for: Chap8\n",
      "    Skipping empty segment: Chap8\n",
      "  Generating for: Chap9\n",
      "    Skipping empty segment: Chap9\n",
      "  Generating for: Chap10\n",
      "    Skipping empty segment: Chap10\n",
      "  Generating for: Chap11\n",
      "    Skipping empty segment: Chap11\n",
      "  Generating for: Chap12\n",
      "    Skipping empty segment: Chap12\n",
      "  Generating for: Chap13\n",
      "    Skipping empty segment: Chap13\n",
      "  Generating for: Chap14\n",
      "    Skipping empty segment: Chap14\n",
      "  Generating for: Chap15\n",
      "    Skipping empty segment: Chap15\n",
      "  Generating for: Chap16\n",
      "    Skipping empty segment: Chap16\n",
      "  Generating for: Chap17\n",
      "    Skipping empty segment: Chap17\n",
      "  Generating for: Chap18\n",
      "    Skipping empty segment: Chap18\n",
      "  Generating for: Chap19\n",
      "    Skipping empty segment: Chap19\n",
      "  Generating for: Chap20\n",
      "    Skipping empty segment: Chap20\n",
      "  Generating for: Chap21\n",
      "    Skipping empty segment: Chap21\n",
      "  Generating for: Chap22\n",
      "    Skipping empty segment: Chap22\n",
      "  Generating for: Chap23\n",
      "    Skipping empty segment: Chap23\n",
      "  Generating for: Chap24\n",
      "Generating Multi-Track V3: Mood=joy, Form=prelude, Tempo=100, DynShape=crescendo, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap24_prelude_joy.mid [joy/family/prelude @ 100 BPM]\n",
      "    → frankenstein_Chap24_prelude_joy.mid\n",
      "  Generating for: Chap1\n",
      "Generating Multi-Track V3: Mood=neutral, Form=etude, Tempo=80, DynShape=flat, LegatoF=0.85\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap1_etude_neutral.mid [neutral/family/etude @ 80 BPM]\n",
      "    → frankenstein_Chap1_etude_neutral.mid\n",
      "  Generating for: Chap2\n",
      "Generating Multi-Track V3: Mood=anger, Form=etude, Tempo=90, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap2_etude_anger.mid [anger/peace/etude @ 90 BPM]\n",
      "    → frankenstein_Chap2_etude_anger.mid\n",
      "  Generating for: Chap3\n",
      "Generating Multi-Track V3: Mood=sadness, Form=prelude, Tempo=55, DynShape=diminuendo, LegatoF=0.98\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap3_prelude_sadness.mid [sadness/tension/prelude @ 55 BPM]\n",
      "    → frankenstein_Chap3_prelude_sadness.mid\n",
      "  Generating for: Chap4\n",
      "Generating Multi-Track V3: Mood=anger, Form=etude, Tempo=89, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap4_etude_anger.mid [anger/mystery/etude @ 89 BPM]\n",
      "    → frankenstein_Chap4_etude_anger.mid\n",
      "  Generating for: Chap5\n",
      "Generating Multi-Track V3: Mood=suspense, Form=nocturne, Tempo=65, DynShape=trembling, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap5_nocturne_suspense.mid [suspense/tension/nocturne @ 65 BPM]\n",
      "    → frankenstein_Chap5_nocturne_suspense.mid\n",
      "  Generating for: Chap6\n",
      "Generating Multi-Track V3: Mood=fear, Form=etude, Tempo=75, DynShape=subdued_var, LegatoF=0.90\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap6_etude_fear.mid [fear/family/etude @ 75 BPM]\n",
      "    → frankenstein_Chap6_etude_fear.mid\n",
      "  Generating for: Chap7\n",
      "Generating Multi-Track V3: Mood=surprise, Form=etude, Tempo=95, DynShape=sudden_loud, LegatoF=0.75\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap7_etude_surprise.mid [surprise/family/etude @ 95 BPM]\n",
      "    → frankenstein_Chap7_etude_surprise.mid\n",
      "  Generating for: Chap8\n",
      "Generating Multi-Track V3: Mood=fear, Form=prelude, Tempo=75, DynShape=subdued_var, LegatoF=0.90\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap8_prelude_fear.mid [fear/violence/prelude @ 75 BPM]\n",
      "    → frankenstein_Chap8_prelude_fear.mid\n",
      "  Generating for: Chap9\n",
      "Generating Multi-Track V3: Mood=sadness, Form=etude, Tempo=55, DynShape=diminuendo, LegatoF=0.98\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap9_etude_sadness.mid [sadness/tension/etude @ 55 BPM]\n",
      "    → frankenstein_Chap9_etude_sadness.mid\n",
      "  Generating for: Chap10\n",
      "Generating Multi-Track V3: Mood=suspense, Form=prelude, Tempo=65, DynShape=trembling, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap10_prelude_suspense.mid [suspense/tension/prelude @ 65 BPM]\n",
      "    → frankenstein_Chap10_prelude_suspense.mid\n",
      "  Generating for: Chap11\n",
      "Generating Multi-Track V3: Mood=suspense, Form=etude, Tempo=65, DynShape=trembling, LegatoF=0.80\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap11_etude_suspense.mid [suspense/mystery/etude @ 65 BPM]\n",
      "    → frankenstein_Chap11_etude_suspense.mid\n",
      "  Generating for: Chap12\n",
      "Generating Multi-Track V3: Mood=anger, Form=prelude, Tempo=90, DynShape=accented, LegatoF=0.70\n",
      "▶️ Saved Multi-Track V3: background_music_nb\\frankenstein\\frankenstein_Chap12_prelude_anger.mid [anger/mystery/prelude @ 90 BPM]\n",
      "    → frankenstein_Chap12_prelude_anger.mid\n",
      "  Generating for: Chap13\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 3: chapter/scene → form+emotion → background MIDI\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Ensure 'gen' is instantiated from Cell 1 ---\n",
    "# gen = FormAwareTextToMusic() # If not already run from a previous cell or if kernel restarted\n",
    "\n",
    "OUT = Path(\"background_music_nb\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "def roman_to_int(s):\n",
    "    \"\"\"Converts a Roman numeral string to an integer.\"\"\"\n",
    "    if not s: return 0\n",
    "    s = s.upper()\n",
    "    roman_map = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n",
    "    i = 0\n",
    "    num = 0\n",
    "    while i < len(s):\n",
    "        s1 = roman_map.get(s[i], 0)\n",
    "        if (i + 1) < len(s):\n",
    "            s2 = roman_map.get(s[i + 1], 0)\n",
    "            if s1 >= s2:\n",
    "                num = num + s1\n",
    "                i = i + 1\n",
    "            else:\n",
    "                num = num + s2 - s1\n",
    "                i = i + 2\n",
    "        else:\n",
    "            num = num + s1\n",
    "            i = i + 1\n",
    "    return num if num > 0 else None # Return None if conversion fails or results in 0\n",
    "\n",
    "def parse_act_scene_heading(heading_text):\n",
    "    \"\"\"\n",
    "    Parses Act and Scene numbers from a heading.\n",
    "    Returns (act_num_str, scene_num_str) or (None, None).\n",
    "    Tries to handle Roman and Arabic numerals.\n",
    "    \"\"\"\n",
    "    act_num_str, scene_num_str = None, None\n",
    "\n",
    "    # Try to find \"ACT X SCENE Y\" type patterns\n",
    "    act_scene_match = re.search(\n",
    "        r\"ACT\\s+(?P<act>[IVXLCDM\\d]+)[\\.,\\s]*SCENE\\s+(?P<scene>[IVXLCDM\\d]+)\",\n",
    "        heading_text, re.IGNORECASE\n",
    "    )\n",
    "    if act_scene_match:\n",
    "        act_str = act_scene_match.group(\"act\").strip().upper()\n",
    "        scene_str = act_scene_match.group(\"scene\").strip().upper()\n",
    "        \n",
    "        act_num = roman_to_int(act_str) if not act_str.isdigit() else int(act_str)\n",
    "        scene_num = roman_to_int(scene_str) if not scene_str.isdigit() else int(scene_str)\n",
    "        \n",
    "        if act_num: act_num_str = f\"Act{act_num}\"\n",
    "        if scene_num: scene_num_str = f\"Scene{scene_num}\"\n",
    "        return act_num_str, scene_num_str\n",
    "\n",
    "    # Try to find standalone \"ACT X\"\n",
    "    act_match = re.search(r\"^\\s*ACT\\s+(?P<act>[IVXLCDM\\d]+)\", heading_text, re.IGNORECASE | re.MULTILINE)\n",
    "    if act_match:\n",
    "        act_str = act_match.group(\"act\").strip().upper()\n",
    "        act_num = roman_to_int(act_str) if not act_str.isdigit() else int(act_str)\n",
    "        if act_num: act_num_str = f\"Act{act_num}\"\n",
    "\n",
    "    # Try to find standalone \"SCENE Y\" (often follows an Act heading)\n",
    "    scene_match = re.search(r\"^\\s*SCENE\\s+(?P<scene>[IVXLCDM\\d]+)\", heading_text, re.IGNORECASE | re.MULTILINE)\n",
    "    if scene_match:\n",
    "        scene_str = scene_match.group(\"scene\").strip().upper()\n",
    "        scene_num = roman_to_int(scene_str) if not scene_str.isdigit() else int(scene_str)\n",
    "        if scene_num: scene_num_str = f\"Scene{scene_num}\"\n",
    "        \n",
    "    return act_num_str, scene_num_str\n",
    "\n",
    "\n",
    "def split_into_segments(text_content):\n",
    "    \"\"\"\n",
    "    Splits text into segments, trying Chapter headings first, then Act/Scene.\n",
    "    Returns a list of (segment_identifier_str, segment_text_str) tuples.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    \n",
    "    # Try Chapter splitting first\n",
    "    # Regex to find \"Chapter X\" and capture X and the text until the next chapter or end of file.\n",
    "    # It looks for \"Chapter\" followed by one or more word characters (for I, II, One, Two, etc.)\n",
    "    # or digits, and then captures everything up to the next \"Chapter\" or the end of the string.\n",
    "    chapter_pattern = re.compile(\n",
    "        r\"(Chapter\\s+([IVXLCDM\\d\\w]+(?:[\\s-][IVXLCDM\\d\\w]+)*)[\\.\\s\\n]*)([\\s\\S]*?)(?=(?:Chapter\\s+[IVXLCDM\\d\\w])|\\Z)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    chapter_matches = list(chapter_pattern.finditer(text_content))\n",
    "\n",
    "    if chapter_matches:\n",
    "        print(\"Detected Chapter structure.\")\n",
    "        for i, match in enumerate(chapter_matches):\n",
    "            chapter_title_full = match.group(1).strip() # Full \"Chapter X\"\n",
    "            chapter_num_text = match.group(2).strip() # Just \"X\"\n",
    "            segment_text = match.group(3).strip()\n",
    "            identifier = f\"Chap{chapter_num_text.replace(' ', '_')}\"\n",
    "            segments.append((identifier, segment_text))\n",
    "        return segments\n",
    "\n",
    "    # If no chapters, try Act/Scene splitting\n",
    "    # This regex looks for \"ACT X\" or \"SCENE Y\" possibly followed by a dot or newline.\n",
    "    # It splits the text based on these headings.\n",
    "    # The (?im) flags enable case-insensitive and multiline matching.\n",
    "    # The lookahead `(?=ACT\\s|\\Z)` ensures we split correctly.\n",
    "    # This is more complex, so we'll iterate and manage current act.\n",
    "    \n",
    "    print(\"No chapters found, trying Act/Scene structure.\")\n",
    "    # Split by lines that start with ACT or SCENE\n",
    "    # A more robust way is to find all ACT and SCENE headings first\n",
    "    \n",
    "    # Find all potential headings\n",
    "    potential_headings = []\n",
    "    for match in re.finditer(r\"^(ACT\\s+[IVXLCDM\\d]+(?:[\\.,\\s]*SCENE\\s+[IVXLCDM\\d]+)?|SCENE\\s+[IVXLCDM\\d]+)\", text_content, re.IGNORECASE | re.MULTILINE):\n",
    "        potential_headings.append({'text': match.group(0).strip(), 'start': match.start(), 'end': match.end()})\n",
    "\n",
    "    if not potential_headings:\n",
    "        # No recognizable Act/Scene structure, treat as a single segment\n",
    "        print(\"No Act/Scene structure found, treating as single segment.\")\n",
    "        return [(\"Segment1\", text_content.strip())]\n",
    "\n",
    "    # Sort headings by their start position\n",
    "    potential_headings.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    current_act_str = \"Act0\" # Default if no Act heading found before first scene\n",
    "    \n",
    "    for i, heading_info in enumerate(potential_headings):\n",
    "        heading_text = heading_info['text']\n",
    "        segment_start = heading_info['end'] # Text starts after the heading\n",
    "        \n",
    "        # Determine end of this segment\n",
    "        if (i + 1) < len(potential_headings):\n",
    "            segment_end = potential_headings[i+1]['start']\n",
    "        else:\n",
    "            segment_end = len(text_content)\n",
    "            \n",
    "        segment_text = text_content[segment_start:segment_end].strip()\n",
    "\n",
    "        act_str, scene_str = parse_act_scene_heading(heading_text)\n",
    "\n",
    "        if act_str:\n",
    "            current_act_str = act_str # Update current act\n",
    "        \n",
    "        if scene_str: # If it's a scene heading (or Act X Scene Y)\n",
    "            identifier = f\"{current_act_str}_{scene_str}\"\n",
    "        elif act_str and not scene_str: # If it's just an ACT X heading, maybe text follows before SCENE I\n",
    "            identifier = f\"{act_str}_Intro\" # Or handle as part of next scene\n",
    "            # Often, an \"ACT X\" heading is immediately followed by \"SCENE I\"\n",
    "            # If segment_text is very short or just stage directions before Scene I, might skip.\n",
    "            if len(segment_text) < 100 and \"SCENE\" in text_content[segment_end:segment_end+50].upper():\n",
    "                 continue # Skip minor text between ACT and first SCENE\n",
    "        else: # Should not happen if regex is good\n",
    "            identifier = f\"UnknownSegment{i+1}\"\n",
    "            \n",
    "        if segment_text: # Only add if there's text\n",
    "            segments.append((identifier, segment_text))\n",
    "            \n",
    "    if not segments and text_content: # Fallback if splitting logic failed but text exists\n",
    "         return [(\"CompleteText\", text_content.strip())]\n",
    "    return segments\n",
    "\n",
    "\n",
    "# --- Main Loop in Cell 3 ---\n",
    "# Ensure 'gen' is instantiated from Cell 1\n",
    "if 'gen' not in locals(): # Check if gen exists, if not, instantiate it\n",
    "    print(\"Instantiating FormAwareTextToMusic in Cell 3...\")\n",
    "    gen = FormAwareTextToMusic()\n",
    "\n",
    "\n",
    "for book_path in Path(\"books\").glob(\"*.txt\"):\n",
    "    print(f\"\\nProcessing book: {book_path.name}\")\n",
    "    text_content = book_path.read_text(encoding=\"utf-8\")\n",
    "    \n",
    "    # Use the new splitting function\n",
    "    # segments is a list of (identifier, text_segment) tuples\n",
    "    segments = split_into_segments(text_content)\n",
    "\n",
    "    if not segments:\n",
    "        print(f\"Could not segment book: {book_path.name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    book_output_dir = OUT / book_path.stem\n",
    "    book_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for seg_idx, (segment_id, segment_text) in enumerate(segments):\n",
    "        print(f\"  Generating for: {segment_id}\")\n",
    "        if not segment_text.strip():\n",
    "            print(f\"    Skipping empty segment: {segment_id}\")\n",
    "            continue\n",
    "\n",
    "        # Unpack all 14 values from analyze_text (ensure this matches your Cell 1's analyze_text return)\n",
    "        try:\n",
    "            (analyzed_mood, analyzed_topic, analyzed_form, \n",
    "            analyzed_melody_scale, analyzed_tempo, analyzed_density, \n",
    "            analyzed_melody_vr, analyzed_accomp_vr, analyzed_mrh, \n",
    "            analyzed_prog_template, analyzed_harmony_roots, \n",
    "            analyzed_is_major, analyzed_dynamic_shape, \n",
    "            analyzed_legato_intensity, analyzed_base_dur_mult) = gen.analyze_text(segment_text)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error analyzing text for {segment_id}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Sanitize segment_id for filename (remove spaces, special chars if any)\n",
    "        safe_segment_id = re.sub(r'[^\\w\\.-]', '_', segment_id)\n",
    "        outm_filename = book_output_dir / f\"{book_path.stem}_{safe_segment_id}_{analyzed_form}_{analyzed_mood}.mid\"\n",
    "        \n",
    "        try:\n",
    "            gen.text_to_midi(segment_text, str(outm_filename), \n",
    "                             form_override=analyzed_form, \n",
    "                             emotion_override=analyzed_mood) # Pass analyzed_mood as emotion_override\n",
    "            print(f\"    → {outm_filename.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Error generating MIDI for {segment_id}: {e}\")\n",
    "\n",
    "print(\"\\n✅ All text segments processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668904dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
